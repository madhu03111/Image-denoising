import os
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, losses, Model
from tensorflow.keras.metrics import MeanSquaredError, MeanAbsoluteError
from PIL import Image
import matplotlib.pyplot as plt


def image_generator(folder, batch_size=4):
    while True:
        images = []
        for filename in os.listdir(folder):
            img_path = os.path.join(folder, filename)
            if img_path.endswith(".png") or img_path.endswith(".jpg"):
                img = Image.open(img_path).convert('L')  # Convert to grayscale
                img = np.array(img).astype('float32') / 255.0  # Normalize
                images.append(img)
                if len(images) == batch_size:
                    yield np.expand_dims(np.array(images), axis=-1), np.expand_dims(np.array(images), axis=-1)
                    images = []
        if len(images) > 0:
            yield np.expand_dims(np.array(images), axis=-1), np.expand_dims(np.array(images), axis=-1)

# Define PSNR function
def psnr(y_true, y_pred):
    max_pixel = 1.0  # Assuming that the images are normalized to [0, 1]
    mse = tf.keras.backend.mean(tf.keras.backend.square(y_true - y_pred))
    return 20 * tf.keras.backend.log(max_pixel / tf.keras.backend.sqrt(mse)) / tf.keras.backend.log(10.0)

# Paths to dataset
train_low = r'Train\low'
train_high = r'Train\high'
test_low = r'Test\Low'
test_high = r'Test\High'

# Create image data generators
batch_size = 4
train_generator = image_generator(train_low, batch_size=batch_size)
test_generator = image_generator(test_low, batch_size=batch_size)

# Define U-Net model
def unet_model(input_shape):
    inputs = tf.keras.Input(shape=input_shape)

    # Downsample blocks
    conv1 = layers.Conv2D(32, 3, activation='relu', padding='same')(inputs)
    conv1 = layers.Conv2D(32, 3, activation='relu', padding='same')(conv1)
    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)

    conv2 = layers.Conv2D(64, 3, activation='relu', padding='same')(pool1)
    conv2 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv2)
    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)

    # Upsample blocks
    up1 = layers.Conv2DTranspose(32, 2, strides=(2, 2), padding='same')(pool2)
    up1 = layers.concatenate([up1, conv2], axis=3)
    conv3 = layers.Conv2D(32, 3, activation='relu', padding='same')(up1)
    conv3 = layers.Conv2D(32, 3, activation='relu', padding='same')(conv3)

    up2 = layers.Conv2DTranspose(16, 2, strides=(2, 2), padding='same')(conv3)
    up2 = layers.concatenate([up2, conv1], axis=3)
    conv4 = layers.Conv2D(16, 3, activation='relu', padding='same')(up2)
    conv4 = layers.Conv2D(16, 3, activation='relu', padding='same')(conv4)

    outputs = layers.Conv2D(1, 1, activation='sigmoid')(conv4)

    model = tf.keras.Model(inputs=inputs, outputs=outputs)
    return model

# Instantiate the U-Net model
unet = unet_model((None, None, 1))

# Compile the model
unet.compile(optimizer='adam', loss=losses.MeanSquaredError(), metrics=[psnr, MeanSquaredError(), MeanAbsoluteError()])

# Train the model using generators
history = unet.fit(train_generator,
                   steps_per_epoch=12,  
                   epochs=25, 
                   validation_data=test_generator,
                   validation_steps=6)  

# Evaluating the model

results = unet.evaluate(test_generator, steps=50)

# Extract specific metrics from the results
test_loss = results[0]
test_psnr = results[1]
test_mse = results[2]
test_mae = results[3]

print(f"Test Loss: {test_loss:.4f}")
print(f"Test PSNR: {test_psnr:.2f} dB")
print(f"Test MSE: {test_mse:.4f}")
print(f"Test MAE: {test_mae:.4f}")

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

